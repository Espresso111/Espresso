{
    "name": "llama_1.3b_-5242454243122376830",
    "num_layers": 23,
    "n_head": 16,
    "hidden_dim": 2048,
    "vocab_size": 32000,
    "max_seq_len": 4096,
    "model_type": "llama"
}